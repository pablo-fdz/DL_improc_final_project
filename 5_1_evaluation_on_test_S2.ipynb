{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0598af90",
   "metadata": {},
   "source": [
    "Evaluating the model trained with **Sentinel-2 L2A** data (natural-looking images)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46647971",
   "metadata": {},
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884fdfe2",
   "metadata": {},
   "source": [
    "## 0.1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a7920e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Seed set to 42 for NumPy, Torch and Random for reproducibility.\n"
     ]
    }
   ],
   "source": [
    "# Utilities\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Deep learning\n",
    "import torch\n",
    "from torch import nn, utils\n",
    "from torchmetrics import classification\n",
    "\n",
    "# Custom library\n",
    "from library import nn_model, utilities, visualizations, preprocessing\n",
    "\n",
    "# Device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "device = torch.device(device)\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Utilities\n",
    "# classes = {0:'non-building', 255:'building'}\n",
    "seed = 42\n",
    "utilities.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e47ead",
   "metadata": {},
   "source": [
    "## 0.2. Setting the path to the data\n",
    "\n",
    "We set the path to the tiles that have been created in the preprocessing notebook, `3_preprocessing.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f599fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_input_dir = '/media/pablo/Shared files/data/'  # Adjust this path to your data directory containing the labelled dataset\n",
    "input_labelled_dir = os.path.join(base_input_dir, 'Satellite_burned_area_dataset')  # Path to the original labelled dataset\n",
    "tile_dir = os.path.join(base_input_dir, 'tiled_labelled_dataset')  # Path to the tiled dataset\n",
    "sentinel_type = 2  # Sentinel-2 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9796b8",
   "metadata": {},
   "source": [
    "## 0.3. Notebook description\n",
    "\n",
    "In this notebook we evaluate the model trained on Sentinel-2 L2A images on the test split made in that notebook.\n",
    "\n",
    "> For consistency, in this notebook we again create the same split in the same way, but in this case we will only be using the test data. **Please ensure that the seeds set in both notebooks are the same for avoiding data leakage and creating the same test set in both notebooks**. Furthermore, pre-processing must be implemented in the same way as for the training notebook with Sentinel-2 L2A images."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
