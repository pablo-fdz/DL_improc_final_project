{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c66e0cf",
   "metadata": {},
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9229881",
   "metadata": {},
   "source": [
    "## 0.1. Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15847d20",
   "metadata": {},
   "source": [
    "## 0.2. Notebook description\n",
    "\n",
    "We train a multi-class segmentation model that assesses wildfire severity using satellite images. Additional steps applied during training:\n",
    "- Randomly shuffle the tiles (done at the training stage).\n",
    "- Apply data augmentation techniques to improve the robustness of the model. The authors implement the following transformations (we will do similar but different ones, this is just as reference): \"*We applied the following transformations: rotation (up to 50° on both sides), shear (up to 20°), horizontal flip, and vertical flip, all of them with a probability of 50%.*\"\n",
    "- If computationally feasible, we will do cross-fold validation. Otherwise, we will just divide the data statically into training, validation and test. The authors use \"*a 7-fold cross-validation approach [...]: 5 folds were used as a training set, 1 fold as a validation set, and 1 fold as a test set.*\"\n",
    "- Adjust the training hyperparameters: \"*16GB. The training was performed using 50 epochs, the Adam optimizer with a learning rate of 0.0001 with no weight decay. The Dice loss was used for training. [...] We implemented an early stopping mechanism with patience of 5 epochs and tolerance of 0.01 on validation loss. The final evaluation is performed on the test set.*\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
